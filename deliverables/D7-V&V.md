# D7 Verification & Validation

Grading: 40 points
Structure your deliverable according to the following sections. See the “Team Project
Instructions” for details about formatting. Check the lecture materials and perform additional
research to produce a high-quality deliverable. As usual, if you have any questions, let me know.

## 1. Description
Provide 1-2 paragraphs to describe your system. This will help us to remember what your
system is about.

Grading: 1 point. Criteria: completeness, language.

## 2. Verification (tests)
Verification aims to ensure that you correctly developed the product.

### 2.1. Unit test
A unit test is an automated test that aims to verify the behavior of a component isolated
from the rest of the system. For this deliverable, you should have automated tests for the
main components of your project. Provide the following information:

* 2.1.1. Test framework you used to develop your tests (e.g., JUnit, unittest, pytest,
etc.):
* 2.1.2. Link to your GitHub folder where your automated unit tests are located.
* 2.1.3. An example of a test case that makes use of mock objects. Include in your
answer a GitHub link to the class being tested and to the test.
* 2.1.4. A print screen showing the result of the unit tests execution.

Grading: 8 points. Criteria: adequate choice of a test framework, coverage of the tests,
quality of the tests, adequate use of Mock objects, print screen showing successful tests
execution.

### 2.2. Integration test
An integration test is an automated test that verifies the implementation of a business rule
that involves multiple components with the goal of certifying that they work together to
produce the expected result. They are often performed in the same test platform as the
unit tests. Provide the following information:

* 2.2.1. Test framework you used to develop your tests:
* 2.2.2. Link to your GitHub folder where your automated integration tests are
located.
* 2.2.3. An example of an integration test. Include in your answer a GitHub link to the
test and an explanation about what parts of the system are being exercised by
this test.
* 2.2.4. A print screen showing the result of the integration tests execution.

Grading: 5 points. Criteria: adequate choice of a test framework, coverage of the tests,
quality of the tests, adequate example of an integration test, print screen showing
successful tests execution.

### 2.3. Acceptance
An acceptance test is a test that verifies the correct implementation of a feature from the
user interface perspective. An acceptance test is a black box test (the system is tested
without knowledge about its internal implementation). Provide the following information:

* 2.3.1. Test framework you used to develop your tests (e.g., Selenium, Katalon
Studio, Espresso2, Cucumber, etc.):
* 2.3.2. Link to your GitHub folder where your automated acceptance tests are
located.
* 2.3.3. An example of an acceptance test. Include in your answer a GitHub link to
the test and an explanation about the tested feature.
* 2.3.4. A print screen/video showing the acceptance test execution.

Grading: 8 points. Criteria: adequate choice of a test framework, coverage of the tests,
quality of the tests, adequate example of an acceptance test, print screen/video showing
successful tests execution.

## 3. Validation (user evaluation)
Validation aims to ensure that you developed the right product. You started the software
inception by talking to users and stakeholders. Now it is time to check if you are on the
right track by conducting some user evaluation on the actual system. Include in this
deliverable the following information:

Script: The script should have the tasks that you will give to the user, what you are going
to collect, and what you are going to ask. Do not forget to add questions about the users’
general impressions. You can ask open questions (e.g., How would you describe the
homepage of our app? How do you compare our system to the competitor X?) or closed
questions (On a scale of 1 to 10, how would you rate the layout of our application? On
the same scale, how likely would you use the system in its current state?). Take a look at
the inception and requirements deliverables to help create the script (aim to check if you
are achieving your initial goals and if the features are implemented in a satisfactory way).

Results: Conduct the user evaluation with at least 3 users. Report the data that you
collected.

Reflections: Reflect on what you observed. Some questions that you can explore: What
features worked well? What can be changed? How is the learning curve of your system?
Did the users preform the tasks as you expected? Did the users’ actions produce the 
results they expected? What did the users like the most? Is your value proposition
accomplished?

### Script

1. What do you think about how the webpage looks?
2. Is it easy to locate what you are looking for on the webpage?
3. What was difficult about it?
4. When filling out the email form, was it easy to fill out?
5. How would you rate the overall ease of use (1 to 10)
6. What could be improved?
7. Would you use it currently, or wait for it to be developed more? Why or why not?
8. What would be the overall score 1-10?
9. Why did you give it this score?
10. Is there anything you would like to add if you were a shopper trying to get notified about a restock? 

### Results
**User: Rhianna Pedro**
1. What do you think about how the webpage looks?
Plain. Everything is white, needs color or some pictures. 
2. Is it easy to locate what you are looking for on the webpage?
Yes, it easily says what to navigate 
3. What was difficult about it?
Nothing
4. When filling out the email form, was it easy to fill out?
Yes super easy, because I just needed to put the email and it told me to check my email afterwards. 
5. How would you rate the overall ease of use (1 to 10)
10
6. What could be improved?
The overall look of the website
7. Would you use it currently, or wait for it to be developed more? Why or why not?
Wait for it to be more developed because you want to see more products and have it be more appealing. 
8. What would be the overall score 1-10?
8.5
9. Why did you give it this score?
Because of how the website looks
10. Is there anything you would like to add if you were a shopper trying to get notified about a restock? 
Just more product options and reviews. 

**User: Kolin Galdiano**
1. What do you think about how the webpage looks?
Simple, because it is very plain with very few texts and no images. 
2. Is it easy to locate what you are looking for on the webpage?
Yes, since there are tabs on the top of the page
3. What was difficult about it?
Nothing since it is prettty simple
4. When filling out the email form, was it easy to fill out?
Yes, because since it is only a 1 step process then I can get notified. 
5. How would you rate the overall ease of use (1 to 10)
10, super easy to use
6. What could be improved?
Add more products and add more to the webpage. 
7. Would you use it currently, or wait for it to be developed more? Why or why not?
Wait for it to be more developed so that there could be products and bigger reputation of people using the program.
8. What would be the overall score 1-10?
8
9. Why did you give it this score?
Because it looks unfinished 
10. Is there anything you would like to add if you were a shopper trying to get notified about a restock? 
Have reviews from customers on the homepage about our website saying, “AlertX was able to get me an exclusive graphics card, which is usually hard to get!” Maybe being able to create a profile to see the items that I have saved for a restock would be nice. 

### Reflections
**User: Rhianna Pedro**
The feedback from Rhianna, we realized that we needed a much more appealing design to our website. Her initial thoughts on the website were mostly about appearance. The more she looked at it, the more she kept talking about wanting more color and pictures. We didn't have much time to fully make the website look appealing or nice, and that's what she noticed as well. 

**User: Kolin Galidiano**
Kolin's feedback focused on the appearance of the website and functionality. He also noticed that the website looked plain but he liked the simplicty of the webpage and how it was easy to navigate everything. However, he did make some suggestions about what we could add to our webpage. He said that we could add more products and some reviews to the home page about customers liking our application so that people are more attracted to our services. He also suggested a "Profile" page for users to save the items they want restock notifications on. Kolin really looks forward to AlertX being more developed and having a bigger reputation.

Grading: 18 points. Criteria: adequate script, adequate report of the results, adequate
reflection, language.
